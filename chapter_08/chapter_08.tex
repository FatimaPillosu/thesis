%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{General discussions}
\label{general_discussions}
\graphicspath{{chapter_08/figures}{chapter_08/tables}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


Flash \marginpara{Escalating flash flood impacts and climate-change-induced intensification of flash flood risk demand urgent advances in forecasting capabilities} floods represent the deadliest and most devastating form of natural hazard worldwide, causing over 5,000 fatalities annually and accounting for approximately 85\% of global flood incidents. Recent catastrophic events, such as those including (but not limited to) the flash floods in Spain, Libya, Germany, Central Asia, and Brazil, have claimed hundreds of lives, thousands of injuries, and billions in economic losses. As climate change continues to intensify the frequency and severity of extreme rainfall - including in historically low-risk regions - the development of accurate, timely, and globally accessible flash flood predictions has become a critical priority for disaster risk reduction. WMO has identified flash floods as one of its top priority natural hazards. Meanwhile, the UN's 'Early Warnings for All' initiative, launched in 2022 with the ambitious goal of protecting every person on Earth with early warning systems by 2027, places flash floods at the forefront of its agenda.

Significant \marginpara{Thesis aim: addressing technical barriers to medium-range predictions of areas at risk of flash floods over a continuous global domain to provide a viable pathway for protecting vulnerable communities worldwide} technical and methodological obstacles persist in developing medium-range flash flood forecasts over continuous global domains. The overall aim of this thesis was to address the critical gap in global flash flood early warning capabilities and to demonstrate how data-driven approaches, combined with global numerical weather prediction models, can provide a viable pathway for protecting vulnerable communities worldwide, particularly those in data-scarce regions where traditional forecasting approaches face significant limitations. These three interconnected research objectives have been addressed in the main analysis chapters of this thesis:

\begin{tcolorbox}[
  colframe=colour_chapter5,  
  colback=white,           
  sharp corners,        
  boxrule=2mm,          
  left=0mm,             
  right=0mm,            
  toprule=0mm,          
  bottomrule=0mm,       
  rightrule=2mm        
]
{\color{colour_chapter5} {\setlength{\parindent}{1.0em} Chapter 5: depart from the traditional rainfall-to-rainfall verification approach and adopt, instead, a \textit{flash-flood-focused verification framework} that directly compares rainfall forecasts with flash flood impact reports to answer research question n.1 (RQ1) "Can post-processed global NWP rainfall forecasts successfully identify areas at risk of flash floods up to medium-range lead times?"}}
\end{tcolorbox}

\begin{tcolorbox}[
  colframe=colour_chapter6,  
  colback=white,           
  sharp corners,        
  boxrule=2mm,          
  left=0mm,             
  right=0mm,            
  toprule=0mm,          
  bottomrule=0mm,       
  rightrule=2mm        
]
{\color{colour_chapter6} {\setlength{\parindent}{1.0em} Chapter 6: develop data-driven models that integrate hydro-meteorological variables from global reanalysis and global medium-range NWP forecasts, and flash flood impact reports to predict areas at risk of flash floods, from short (i.e., day 1) to medium-range lead times (i.e., day 5), to answer research question n.2 (RQ2) "Are medium-range data-driven hydro-meteorological predictions of areas at risk of flash floods feasible with global reanalysis, forecasts, and impact flash flood reports?"}}
\end{tcolorbox}

\begin{tcolorbox}[
  colframe=colour_chapter7,  
  colback=white,           
  sharp corners,        
  boxrule=2mm,          
  left=0mm,             
  right=0mm,            
  toprule=0mm,          
  bottomrule=0mm,       
  rightrule=2mm        
]
{\color{colour_chapter7} {\setlength{\parindent}{1.0em} Chapter 7: assess how varying spatial coverage and data density scenarios may influence training strategies when creating global predictions with regionally-trained data-driven models, to answer research question n.3 (RQ3) "How does coverage-density trade-off influence training data strategies to develop predictions of areas at risk of flash floods over a continuous global domain?"}}
\end{tcolorbox}

This chapter discusses the outcomes, implications, and limitations of the research from each of these three main analysis chapters, synthesises the broader contributions to flash flood prediction science, and presents recommendations for advancing global early warning capabilities against flash floods that could ultimately save thousands of lives every year and support UN's vision of global early warning coverage - for flash floods.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Development of a flash-flood-focused verification framework for predictions of areas at risk of flash flood against flash flood impact reports}

By addressing RQ1\marginpara{Contribution to knowledge no. 1: creation of a flash-flood-focused verification framework and a benchmark verification dataset for data-driven predictions based on hydro-meteorological parameters}, this thesis introduces a \textit{flash-flood-focused verification framework}, a methodology that directly compares global NWP rainfall predictions with observed flash flood occurrences. Departing from conventional rainfall-to-rainfall verification paradigms, this contribution addresses a methodological gap in the literature given by the implicit assumption that improved rainfall forecasts necessarily enhance flash flood predictions. By implementing this direct comparison between global NWP rainfall predictions and observed flash flood occurrences, we provide empirical evidence of whether advances in numerical weather prediction modelling translate to enhanced flash flood predictability up to medium-range timescales. The investigation employed the CONUS as the primary experimental domain, leveraging the exceptional spatio-temporal resolution and completeness of NOAA's Storm Event Database for objective verification. Moreover, the outcomes of this phase provided a performance benchmark for the short- and medium-range data-driven flash flood predictions developed at the later stages of this research.


\subsection{Key insights and contributions}

The most significant finding from this research demonstrates that global NWP models, specifically ERA5 when post-processed through the ecPoint technique, can indeed identify areas at risk of flash floods with meaningful skill up to medium-range (day 5) lead times. The values of AUC-ROC consistently above 0.6 across all lead times establish that useful predictive information persists throughout the medium-range forecast horizon. Hence, this finding challenges the prevailing assumption that flash flood prediction must require high-resolution forecasts. Similar results were also obtained by \citet{Pillosu_2024} when ECMWF' Ensemble rainfall forecasts and their post-processed version with ecPoint were evaluated against flash flood reports in Ecuador. 

The identification of optimal return period thresholds also represents a crucial operational contribution. The analysis reveals that extreme rainfall events exceeding 20- and 50-year return periods achieve frequency bias values between 2 and 3, approaching the ideal value of unity far more closely than lower return periods. This convergence towards optimal reliability at extreme thresholds provides two potential interpretations that merit consideration. First, the rainfall-based predictions may genuinely perform best when focused on the most extreme events, as these create sufficiently severe hydrological conditions to overwhelm local modulating factors such as soil moisture or drainage capacity. Second, the Storm Event Database may predominantly capture only the most severe flash flood events, with routine or moderate events systematically underreported. The inability to definitively distinguish between these interpretations highlights a fundamental challenge in verification against impact databases. 

The verification framework developed in Chapter 5 itself constitutes a transferable methodological contribution that extends beyond the specific findings for the considered global rainfall forecasts (ERA5-ecPoint) and the considered hazard (flash floods). By establishing standardised procedures for transforming point-based impact reports into gridded observational fields, defining verifying thresholds from climatological data as done in this thesis or from short-range forecasts as shown by \citet{Pillosu_2024}), and computing both reliability and discrimination metrics, this research provides a blueprint for evaluating any 
rainfall predictions (see examples from \citep{Pillosu_2024}) and other hazards with minimal adaptations to the methodology (see examples for severe weather in \citet{Robbins_2018} and \citet{Tsonevsky_2018} for severe weather and \citet{Cavaiola_2024} for lightning). Possible modifications to the methodology proposed here might include ways to account for location and time uncertainties in the impact reports if forecasts with much higher spatial and temporal resolution are considered. In this specific development, such uncertainties did not play a crucial role as the forecasts were provided over ERA5's low spatial resolution grid (\sim31 km) and over 24-hourly outlooks, which can counterbalance the inherent uncertainties in reporting uncertainties.

\subsection{Limitations}

The verification was conducted exclusively over the CONUS, leveraging the exceptional quality and spatial coverage of NOAA's Storm Event Database. While this does not limit the potential transferability of both the verification framework and the established performance metrics, the return period thresholds found in this thesis might not hold in other parts of the world. 

Some issues can also be anticipated over the CONUS. Despite the fairly good completeness of the Storm Event Database, the inherent biases in impact reporting — including population density effects, diurnal reporting variations, and socio-economic disparities in hazard documentation \citep{} — introduce systematic uncertainties that the developed verification framework cannot fully quantify. The fundamental assumption that the absence of reports equates to the absence of events inevitably inflates false alarm rates, as locations experiencing flash floods without documentation are classified as false positives. This effect compounds in rural or economically disadvantaged areas where reporting infrastructure is limited, creating a spatially heterogeneous bias field that may correlate with the very vulnerabilities the warning system aims to address. The resulting frequency bias values, while useful for relative comparison across thresholds and lead times, likely present an overly pessimistic view of true forecast performance.

The rainfall-only approach, whilst demonstrating good predictive skill, fundamentally neglects the hydrological processes that modulate rainfall-runoff transformation. Antecedent soil moisture conditions, land surface characteristics, urbanisation extent, and drainage network properties all influence whether a given rainfall event triggers flash flooding, yet these factors remain unaccounted for in this chapter. By neglecting these factors, the rainfall-only approach may miss critical flash flood events in pre-saturated catchments while generating false alarms in areas with high infiltration capacity or robust drainage systems. Hence, the scientific and operational community should strive to develop global forecasts that also incorporate hydrological parameters to identify areas at risk of flash floods better.

\subsection{Future research directions}

Advancing the flash-flood-focused verification framework requires coordinated efforts across multiple research fronts. 

An immediate priority may involve applying the verification framework in other data-rich regions. Verification studies using the European Severe Weather Database over Europe, the Japanese Meteorological Agency records, or the Australian Bureau of Meteorology flood databases would test the universality of the established thresholds for flash-flood- triggering return periods. These studies should explicitly examine how verification metrics vary with different impact reporting systems, hydro-climatic regions, and societal factors affecting report generation.

Another aspect that could be considered is separating verification statistics for large-scale and convective systems. Their predictability is very different \citep{}, and this might impact the outcomes of the verification. The findings of \citet{Pillosu_2024} demonstrate significant performance disparities in flash flood identification across different convective regimes. Their verification statistics reveal that regions dominated by large-scale convective systems — represented in NWP model outputs as large-scale rainfall — exhibit markedly better forecast skill compared to regions impacted primarily by small-scale convective systems. Whilst raw forecasts successfully identified flash flood risk areas in regions with large-scale convection, they demonstrated considerably poorer performance in regions dominated by small-scale convective systems. Moreover, post-processed forecasts with the ecPoint methodology showed their true benefit in the second case, by enhancing the identification of areas at risk of flash floods missed by the raw forecasts. These contrasting outcomes suggest that incorporating in the verification framework rainfall-related discriminators (such as whether the flash flood event was generated by a large- or small-scale system) could provide more nuanced insights into the performance and predictability of global NWP rainfall forecasts for the identification of areas at risk of flash flood.

Alternative post-processing techniques warrant investigation, particularly machine learning-based downscaling methods that could reduce computational demands whilst preserving or enhancing forecast quality. Deep learning architectures trained on the relationship between coarse-resolution NWP outputs and high-resolution precipitation observations could potentially replace the computationally intensive weather regime matching of ecPoint. Finally, developing bias correction methodologies for impact databases—potentially through integration of satellite-based flood detection, social media mining, and population density weighting—could address the systematic underreporting that affects verification metrics, providing more accurate assessments of true forecast performance.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Development of data-driven hydro-meteorological predictions of areas at risk of flash flood}

The advancement from rainfall-only predictions to integrated hydro-meteorological modelling represents a critical evolution in flash flood forecasting methodology. Chapter 6 addressed Research Question 2 (RQ2) by demonstrating the feasibility of developing data-driven predictions that successfully handle severe class imbalance whilst incorporating multiple environmental variables to enhance predictive capability. The systematic evaluation of six machine learning architectures, combined with comprehensive hyperparameter optimisation and feature importance analysis, establishes both the potential and constraints of data-driven approaches for operational flash flood prediction at regional scales.

\subsection{Key insights and contributions}

The successful development of a data-driven model using a severely imbalanced observational dataset - with flash flood events representing merely 0.27\% of the whole training dataset - demonstrates that carefully configured machine learning algorithms can extract meaningful predictive signals for flash flood detection from sparse observational datasets, up to medium-range lead times. A few considerations emerge, however, from this achievement.

The comprehensive evaluation across multiple architectures (decision-tree-based, such as random forest and gradient boosting, and neural networks) reveals that gradient boosting implementations and shallow neural networks were able to learn functional patterns in the data to predict areas at risk of flash floods with good discrimination ability and reliability up to medium-range lead times. The analysis of the hyperparameter tuning suggests that simpler architectures were already able to extract the patterns in the data that were needed for the successful prediction of areas at risk of flash floods over a large domain (i.e. the CONUS) and up to medium-range lead times. This is particularly exemplified in the neural networks. Whilst during optimisation, the neural network was allowed to have multiple (>2) hidden layers, the optimisation suggested that one hidden layer was enough to generalise from the data at hand and identify areas at risk of flash floods, even from medium-range forecasts. This result appears to be in striking contrast with the current literature on deep learning for flash flood prediction, suggesting that deep neural networks outperform simpler implementations, such as random forests, gradient boosting and shallow neural networks \citep{}. These studies differ in nature from this research. They aim to predict river discharge for specific catchments to generate high-resolution (< 1 km) inundation maps, thereby identifying potential flooded areas with high precision at very short lead times. The target of this thesis is simpler - it predicts the binary condition of yes or no flash flood occurrence without claiming to be more precise in terms of magnitude and timing of the event. Perhaps, it is for this reason that simpler models can satisfy the basic needs of operational flash flood prediction over large domains - whose aim coincides with the prediction target of this thesis \citep{Zanchetta_2020} - and further the time horizon of the forecasts from day 1 to day 5 predictions. In particular, XGBoost achieved the best balance between predictive performance and computational efficiency, with training times in the order of minutes rather than hours, as was the case with neural networks. In operational hydrology, such a short training time is highly appealing for further training as more observations become available, or more features may need to be tested. 

General and imbalanced-data-specific loss functions were considered to develop the data-driven models presented in Chapter 6. Together with the manipulation of the training dataset to reduce the imbalance between the binary events, the use of loss functions specific for imbalanced datasets is considered standard practice in machine learning to help the data-driven model learning from the features to predict the target variable \citep{Altalhan_2025}. Whilst the first approach - manipulate the training dataset - was not considered in this thesis to avoid adding more uncertainties than those already inherent in the observational and forecast data by creating synthetic yes-event or removing possibly very informative non-events, the second approach - considering loss functions specific for imbalanced datasets - was considered alongside training the model with no specific treatment of the imbalanced characteristic. It was learnt from this comparison that models employing weighted loss functions successfully enhance detection of positive events, achieving hit rates approaching 90\% for gradient boosting implementations. However, this enhanced sensitivity incurred in false alarm rates exceeding 50\%, representing a twenty-fold increase compared to balanced configurations. For flash flood prediction, where public trust and warning fatigue represent critical operational constraints, the conservative approach using balanced loss functions emerges as preferable despite lower detection rates. This finding challenges the assumption that maximising hit rates should be the primary objective in rare event prediction, highlighting instead the importance of maintaining forecast credibility through balanced performance. Moreover, the identification of the areas at most risk of flash flooding was made difficult by the increased noise created by the models trained with weighted loss functions. While in theory, this was not always showing a worsening of the scores, in practice, such forecasts would hold lower value for practitioners (e.g., forecasters) because areas at risk of flash floods would not be highlighted as precisely. 

The integration of hydro-meteorological features beyond precipitation represents a fundamental advance over the rainfall-only baseline established in Chapter 5, and typically used in operational hydrology when identifying areas at risk of flash flood over large domains. Whilst the SHAP analysis confirms that rainfall probability for the 1-year return period dominates model decisions with an 80\% contribution, the secondary features also hold high importance with contributions of 10-35\% to the mean absolute SHAP values, and provide critical modulation of flash flood risk as seen by the dependency maps. The importance of considering hydrological parameters for predicting areas at risk of flash floods is evident in the low importance given to hyperparameters that specify the fraction of features to be randomly sampled while training gradient boosting (colsample\_bytree) and neural networks (dropout). Moreover, values of these hyperparameters mostly remained close to 1 during the multiple optimisations, indicating that the selected features were all important - although at different levels as shown by the SHAP analysis.

The temporal analysis of forecast skill degradation establishes practical boundaries for operational utility across different lead times. The minimal performance reduction from reanalysis to day 1 forecasts demonstrates that short-range (up to t+24) predictions retain good accuracy for high-confidence protective actions. 

 The gradual degradation from day 3 to day 5 forecasts, where discrimination ability remains above 0.7, indicates that medium-range forecasts retain value for preparedness activities despite reduced precision and reliability. This temporal stratification enables differentiated response protocols where immediate evacuations or other high-cost actions such as resource mobilisation might be triggered by day 1 forecasts, whilst day 3-5 predictions may support low-cost, no-regret actions, such as public awareness campaigns.
 

\subsection{Limitations}

\subsection{Future research directions}