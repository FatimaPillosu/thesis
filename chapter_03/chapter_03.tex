%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Integrated experimental strategy}
\label{experimental_design}
\graphicspath{{chapter_03/figures}{chapter_03/tables}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


This chapter outlines the integrated experimental strategy designed to address the research questions presented in Chapter \ref{general_introduction}, thereby providing a proof of concept for medium-range predictions of areas at risk of flash floods across a continuous global domain. The strategy follows a \textit{three-research-component approach}, where each component builds upon the findings of the previous ones (Figure \ref{fig:integrated_experimental_strategy}, rows related to \textit{research questions} and \textit{research components}). 

The \marginpara{First research component (addressing RQ1): development of a flash-flood-focused verification framework to assess predictions of areas at risk of flash flood} first research component addresses the development of a flash-flood-focused verification framework for rainfall forecasts, designed to benchmark the capability of medium-range global NWP rainfall forecasts to identify areas at risk of flash floods. This verification framework serves two critical purposes: it first establishes a baseline of how effectively state-of-the-art global NWP models predict rainfall patterns associated with flash flood risk up to medium-range lead times. Second, it provides a benchmark against which more sophisticated predictive systems can be evaluated.

\begin{figure}[htbp]
\centering
\includegraphics[width=\textwidth]{chapter_03/figures/integrated_experimental_strategy.png}
\caption{\textbf{Thesis' integrated experimental strategy.} The infographic presents the hierarchical relationship between research questions (RQ1-RQ3), their corresponding research components, and underlying methodological decisions. The first row reminds the reader about the three research questions addressed in Chapters \ref{flash_flood_focused_verification_framework}, \ref{feasibility_PoFF}, and \ref{predictability_PoFF} (pink, orange, and purple cards, respectively) as introduced in Chapter \ref{general_introduction}. The second row outlines the research components developed to address each RQ. The cards maintain the chapter-specific colour coding. The horizontal arrows beneath the cards indicate the cross-chapter applications as introduced in Chapter \ref{general_introduction}, with colouration denoting chapters where components were employed. The third row (grey horizontal panels within the dashed grey box) identifies the three core methodological decisions that inform the experimental design: data source selection (Section \ref{experimental_data_requirements}), forecast verification strategy (Section \ref{experimental_design_verification_strategy}), and data-driven model development strategy (Section \ref{experimental_design_model_dev_imbalanced_data}). The coloured indicators on the right denote their application across the respective research components.}
\label{fig:integrated_experimental_strategy}
\end{figure}

The \marginpara{Second research component (addressing RQ2): development of short-range (day 1, reanalysis-based) hydro-meteorological, data-driven predictions of areas at risk of flash floods - Regional proof of concept over CONUS and global transferability assessment} second research component proposes a methodology to develop short-range (day 1, reanalysis-based) hydro-meteorological, data-driven predictions of areas at risk of flash floods. Due to data limitations, the methodology was developed over the CONUS. This data-driven approach represents a departure from traditional physically based hydrological modelling, which often struggles with computational demands and parameter uncertainty. In this second research component, a sensitivity analysis is also performed to assess which data strategy would be most suitable for extending the regional training globally, allowing predictions to be computed over a continuous global domain.

The \marginpara{Third research component (addressing RQ3): development of medium-range (up to day 5) hydro-meteorological, data-driven predictions of areas at risk of flash floods - Regional and global prototype} third research component extends the application of the data-driven model to medium-range forecasts, enabling the assessment of flash flood predictability beyond the typical day 1 lead time. This component applies the data-driven model developed in the second research component to longer-range NWP forecasts. It also applies the verification framework developed in the first research component to evaluate how predictive skill decays with increasing lead times. This evaluation is crucial for understanding the temporal limitations of actionable flash flood predictions.

The following sections outline the methodological decisions (Figure \ref{fig:integrated_experimental_strategy}, row related to the \textit{methodological decisions}) underlying each research component. These decisions encompass three primary areas: the selection of appropriate data sources (Section \ref{experimental_data_requirements}), the formulation of the forecast verification strategy (Section \ref{experimental_design_model_dev_imbalanced_data}), and the strategy for developing a data-driven model to identify areas at risk of flash floods under imbalanced observational datasets (Section \ref{experimental_design_model_dev_imbalanced_data}). 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Data requirements and selection}
\label{experimental_data_requirements}

The development of a flash flood prediction system necessitates careful consideration of data requirements across all methodological components, e.g. model development, forecast verification (at different lead times), and future operational implementation. This section outlines the criteria for selecting the required data to develop a proof of concept of a system that produces medium-range forecasts of areas at risk of flash floods over a continuous global domain (Section \ref{experimental_data_requirements_data_selection_criteria}) and provides the final selection within available sources (Section \ref{experimental_data_requirements_final_selection}). 


\subsection{Criteria for data selection}
\label{experimental_data_requirements_data_selection_criteria}

\subsubsection{Requirements for observational data}

Given \marginpara{Requirement for observational data n.1: spatio-temporal accuracy of reported flash flood events} that flash floods are rapid-onset, localised events typically occurring in small catchments, observational datasets must accurately capture both the location and timing of each event, alongside quantifying the spatio-temporal uncertainty associated with each record. This precision is essential for developing a robust flash-flood-focused verification framework (RQ1), where grid-based assessments require accurate spatial assignment of events to model grid cells. Furthermore, precise spatio-temporal information enables prediction systems — whether data-driven or physics-based — to establish meaningful relationships between local meteorological conditions and flash flood occurrence, thereby capturing the fine-scale processes that govern these rapid-onset events (RQ2 and RQ3).

The \marginpara{Requirement for observational data n.2: long, complete, and consistent timeseries of reported events.} rarity of flash flood events necessitates extensive temporal coverage to accumulate an adequate number of flash flood events for robust forecast verification (RQ1 to RQ3) and data-driven model training (RQ2). Additionally, consistent reporting standards across the considered spatial domain ensure unbiased verification and prevent the introduction of artificial patterns during model training. Moreover, consistent reporting standards would facilitate sensitivity analyses for expanding regional training to global scales, should suitable global databases not be available (RQ2).

\subsubsection{Requirements for hydro-meteorological forecasts}

To \marginpara{Requirements for hydro-meteorological forecasts  n.1: consistent forecasts spatial resolution through the lead time horizon} analyse forecast predictability from short-range (i.e., up to day 1; RQ1 and RQ2) to medium-range lead times (up to day 5; RQ1 and RQ3), a system providing consistent spatial resolution across all lead times would be preferable. Varying resolutions would compound extrinsic uncertainties with those intrinsic ones present in flash flood predictions, arising from both the chaotic nature of flash-flood-generating rainfall events and the complexity of the hydrological processes involved in flash flood generation. Hence, by employing consistent spatial resolution throughout, any lead-time-driven model performance degradation may reflect genuine predictability limits rather than dataset inconsistencies.

Due \marginpara{Requirements for hydro-meteorological forecasts  n.2: capability to represent flash-flood-triggering rainfall events} to their coarse resolution and parametrisation schemes of convective systems, raw global NWP model outputs systematically underestimate localised rainfall extremes, which are critical for flash flood generation. Consequently, both the verification of areas at risk of flash floods (RQ1 to RQ3) and the training of machine learning models for predicting such areas at risk of flash floods (RQ2) require rainfall estimates that can identify flash-flood-triggering rainfall events. 

Whilst \marginpara{Requirements for hydro-meteorological forecasts  n.3: Global coverage} the proof of concept proposed in this thesis focuses in the creation (RQ2 and RQ3) and verification (RQ1 to RQ3) of predictions of areas at risk of flash floods over the CONUS, the methodology must support global extension. This requirement necessitates globally consistent datasets without regional discontinuities, typically provided by global NWP model outputs.


\subsection{Available Data Sources and Final Selection}
\label{experimental_data_requirements_final_selection}

\subsubsection{Observational data}

The \marginpara{Choice of observational data: impact-based reports vs gauge-based measurements} observational data available for this thesis fall into two main categories: impact-based reports and gauge-based measurements. The choice of using impact-based reports rather than gauge-based measurements reflects this thesis's objective to predict areas at risk of both fluvial flash floods - occurring within river channels - and pluvial flash floods - resulting from inadequate urban drainage systems or surface runoff accumulation, including areas away from river channels. Discharge gauges capture only fluvial flash floods, whilst impact databases enable the identification of both fluvial and pluvial events. Furthermore, gauge-based observations systematically underestimate flash flood frequency due to a sparse observational network and the tendency for flashy catchments to remain ungauged \citep{Gaume_2009, Gaume_2016}. Although impact databases are subject to reporting biases — notably those related to population density \citep{Marjerison_2016} — they provide the most feasible approach for developing and verifying continental-scale predictions of areas at risk of flash floods.

This \marginpara{Chosen impact database - NOAA's Storm Event Database over CONUS - and its comparison to alternative databases} thesis employs NOAA's Storm Events Database\footnote{For more details, refer to Section \ref{storm_event_database} in Chapter \ref{datasets}} over the CONUS as the primary observational data source. Compared to other impact databases, the Storm Event Database represents the most comprehensive and systematically maintained record of flash flood impacts available at a continental scale, containing detailed spatio-temporal information from 1996 to the present, including location and reporting time uncertainties for each event. The database's consistent reporting standards across all US states, maintained through NOAA quality control procedures, reduce, though do not eliminate, reporting inconsistencies. Such spatial consistency enables robust model development and forecast verification across CONUS' diverse hydro-climatic regions, while also facilitating sensitivity analyses for expanding regional training to a global scale. Whilst alternative databases exist, they present significant limitations. ESSL's ESWD database lacks direct flash flood reports, recording only "extreme rainfall" events \citep{Dotzek_2009}. Such reports are usually considered as proxies for flash flooding. However, as stated in Chapter \ref{general_introduction}, a direct correlation between rainfall events and flash flood generation is not assumed in this thesis. Furthermore, ESWD presents a spatial bias with disproportionately high observation density over Germany, where ESSL is based \citep{Dotzek_2009}. Such a difference is inconsistent with the literature, which provides no evidence of higher flash flood frequency in Germany relative to neighbouring countries \citep{Gaume_2009}. Hence, if ESWD were the primary observational dataset, errors in the spatial representation of areas at risk of flash floods might be introduced during model training and forecast verification. Global impact databases such as EM-DAT and DesInventar contain an insufficient number of flash flood records due to their inclusion criteria and the inherent difficulty of systematically documenting small-scale events worldwide \citep{Panwar_2020}.

\subsubsection{Hydro-meteorological forecasts}

The \marginpara{Chosen reanalysis and forecasting system for hydrological and static parameters - ERA5} selection of ERA5-related datasets\footnote{For more details, refer to Section \ref{datasets_era5} in Chapter \ref{datasets}} (both reanalysis and medium-range forecasts) reflects a deliberate strategy to maintain consistency across the three research components of this thesis. ERA5 provides a long-term (from the 1940s to the present), high-quality reconstruction of hydrological and static fields over a continuous global domain \citep{Hersbach_2020}.  This temporal extent ensures sufficient historical data to capture the full spectrum of meteorological conditions associated with flash flood events, including rare, extreme scenarios that may occur infrequently within shorter time series. The global coverage and uniform spatial resolution of ERA5 eliminate boundary effects and regional inconsistencies that could compromise model transferability across different geographical domains. Furthermore, the availability of medium-range predictions with the same spatial resolution as the reanalysis data used during model training facilitates the analysis of forecast predictability with minimum disruption due to fine-tuning of low-resolution training datasets to higher-resolution forecasts, as seen in other data-driven systems \citep{Lang_2024}.

While \marginpara{Chosen reanalysis and forecasting system to represent localised extreme rainfall - ERA5-ecPoint} ERA5 provides a consistent dataset for training and prediction across space and time, its coarse resolution (31 km) renders raw ERA5 rainfall estimates unsuitable for flash flood applications. Localised rainfall peaks tend to be underestimated in the case of large-scale rainfall (whether from stratiform rainfall or large convective systems) or absent in the case of isolated convection. Hence, the rainfall estimates used in this thesis for training, model development, and verification come from the post-processed ERA5 rainfall estimates with the ecPoint methodology (ERA5-ecPoint\footnote{For more details, refer to Section \ref{datasets_era5_ecpoint} in Chapter \ref{datasets}}). ERA5-ecPoint provides a probabilistic distribution of the localised extreme rainfall estimates that might be observed by rain gauges within model grid-boxes, being, therefore, more representative of point-scale rainfall's local maxima.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Forecasts verification strategy}
\label{experimental_design_verification_strategy}

Moreover \marginpara{Evaluation metrics for forecast verification}, during verification, it might not be possible to understand whether forecasting systems overestimate the frequency of flash flood events due to intrinsic biases in the predictive model or due to the underrepresentation of the hazard occurrence. Performance metrics suitable for balanced datasets become misleading with extreme imbalance. Hence, the use of appropriate verification metrics, such as the combination of precision and recall, might be able to capture meaningful predictive signals of yes-events (cases indicating the occurrence of flash floods).

\subsection{Robust metrics to evaluate rare events using underreporting observational datasets}

Traditional \marginpara{Evaluation metrics for model development} loss functions weigh all misclassifications equally, effectively obscuring the importance of correctly identifying rare positive events. In some contexts, the cost of missing an event might exceed that of a false alarm, while in others, the opposite might be more of a concern due to scarce resources for preparedness ahead of an event and emergency management during the event. Hence, during the development of data-driven predictive models (as in RQ2), approaches that reflect this asymmetry must be considered, such as identifying suitable evaluation metrics for model development. 

\subsection{Final selection}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Data-driven model development strategy under imbalanced observational datasets}
\label{experimental_design_model_dev_imbalanced_data}

\subsection{Robust algorithms to develop data-driven models under imbalanced datasets}


\subsection{Final selection}


The development of data-driven flash flood prediction models must confront the fundamental challenge of extreme class imbalance in observational datasets, stemming from the rarity of events and the underrepresentation of flash flood occurrences in observational timeseries \citep{Gaume_2009, Panwar_2020, Marjerison_2016}. Flash flood events represent approximately 0.2\% of the observational dataset, creating one of the most severe class imbalance problems encountered in environmental prediction, similar to, for example, lightning detection problems \citep{Cavaiola_2024}. This section outlines the strategies employed to address these challenges while ensuring robust and generalisable predictions.

Such \marginpara{Algorithmic convergence to trivial solutions} an imbalance towards non-events (cases indicating the non-occurrence of flash floods) poses significant challenges for machine learning algorithms, which may converge to trivial solutions that never predict positive events. These trivial classifiers achieve an accuracy greater than 99\% by simply predicting non-events for all cases, yet provide no operational value. The challenge lies in developing models that can identify the subtle signals preceding rare events without being overwhelmed by the preponderance of negative cases.

Ensemble \marginpara{Ensemble learning techniques} learning techniques also offer a valid approach to address the class imbalance problem. Unlike data-level approaches that modify the training dataset through over- or under-sampling, ensemble methods preserve the original data distribution whilst improving minority class detection through algorithmic diversity. This choice reflects a deliberate decision to maintain the integrity of the observational dataset, avoiding the introduction of synthetic samples or the loss of potentially informative negative examples. The experimental design incorporates multiple ensemble algorithms, including Random Forest, Gradient Boosting variants (XGBoost, LightGBM, CatBoost), neural networks, and ensemble stacking. Each algorithm offers different mechanisms for handling imbalanced datasets. For example, random forest creates multiple views of the data through bootstrap sampling, where positive events may be better represented in individual trees. Gradient boosting methods sequentially focus on misclassified examples, progressively improving detection of difficult-to-predict positive cases. This diversity enables a comprehensive assessment of which algorithmic approaches best suit the flash flood prediction challenge. Moreover, ensemble methods combine predictions from multiple base learners, each potentially capturing different aspects of the flash flood generation process. This diversity provides robustness against the instabilities that can arise when training individual models on severely imbalanced data.



%%%%%%%%%%%%%%%%%
\section{Summary}

This chapter has articulated an integrated experimental design that systematically addresses the challenge of producing medium-range predictions of areas at risk of flash floods across a continuous global domain. The methodological framework illustrates how seemingly distinct research components converge into a coherent strategy, with each element carefully chosen to support the overarching research questions in this thesis. This integrated design acknowledges that flash flood prediction represents a cascade of uncertainties. By maintaining methodological consistency whilst allowing component-specific optimisation, the framework provides a robust platform for advancing operational flash flood prediction capabilities. The subsequent \textit{Main Analysis} chapters (\ref{flash_flood_focused_verification_framework} to \ref{predictability_PoFF}) will implement this experimental design, progressively building from fundamental verification principles through regional model development of short- and medium-range forecasts, to the extension of predictions over a continuous global domain.