%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Integrated experimental strategy}
\label{experimental_design}
\graphicspath{{chapter_03/figures}{chapter_03/tables}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


This chapter outlines the integrated experimental strategy designed to address the research questions presented in Chapter \ref{general_introduction}, thereby providing a proof of concept for medium-range predictions of areas at risk of flash floods across a continuous global domain. The strategy follows a \textit{three-research-component approach}, where each component builds upon the findings of the previous ones (Figure \ref{fig:integrated_experimental_strategy}, rows related to \textit{research questions} and \textit{research components}). 

The \marginpara{First research component (addressing RQ1): development of a flash-flood-focused verification framework to assess predictions of areas at risk of flash flood} first research component addresses the development of a flash-flood-focused verification framework for rainfall forecasts, designed to benchmark the capability of medium-range global NWP rainfall forecasts to identify areas at risk of flash floods. This verification framework serves two critical purposes: it first establishes a baseline of how effectively state-of-the-art global NWP models predict rainfall patterns associated with flash flood risk up to medium-range lead times. Second, it provides a benchmark against which more sophisticated predictive systems can be evaluated.

\begin{figure}[htbp]
\centering
\includegraphics[width=\textwidth]{chapter_03/figures/integrated_experimental_strategy.png}
\caption{\textbf{Thesis' integrated experimental strategy.} The infographic presents the hierarchical relationship between research questions RQ1, RQ2, and RQ3 (addressed in the main analysis chapters), their contribution to knowledge, and the underlying methodological decisions. The first row reminds the reader about the three research questions addressed in Chapters \ref{flash_flood_focused_verification_framework}, \ref{feasibility_PoFF}, and \ref{predictability_PoFF} (pink, orange, and purple cards, respectively) as introduced in Chapter \ref{general_introduction}. The second row outlines the research components developed to address each RQ. The cards maintain the chapter-specific colour coding. The horizontal arrows beneath the cards indicate the cross-chapter applications as introduced in Chapter \ref{general_introduction}, with colouration denoting chapters where components were employed. The third row (grey horizontal panels within the dashed grey box) identifies the three core methodological decisions that inform the experimental design: data source selection (Section \ref{experimental_data_requirements}), forecast verification strategy (Section \ref{experimental_design_verification_strategy}), and data-driven model development strategy (Section \ref{experimental_design_model_dev_imbalanced_data}). The coloured indicators on the right denote their application across the respective research components.}
\label{fig:integrated_experimental_strategy}
\end{figure}

The \marginpara{Second research component (addressing RQ2): development of short-range (day 1, reanalysis-based) hydro-meteorological, data-driven predictions of areas at risk of flash floods - Regional proof of concept over CONUS and global transferability assessment} second research component proposes a methodology to develop short-range (day 1, reanalysis-based) hydro-meteorological, data-driven predictions of areas at risk of flash floods. Due to data limitations, the methodology was developed over the CONUS. This data-driven approach represents a departure from traditional physically based hydrological modelling, which often struggles with computational demands and parameter uncertainty. In this second research component, a sensitivity analysis is also performed to assess which data strategy would be most suitable for extending the regional training globally, allowing predictions to be computed over a continuous global domain.

The \marginpara{Third research component (addressing RQ3): development of medium-range (up to day 5) hydro-meteorological, data-driven predictions of areas at risk of flash floods - Regional and global prototype} third research component extends the application of the data-driven model to medium-range forecasts, enabling the assessment of flash flood predictability beyond the typical day 1 lead time. This component applies the data-driven model developed in the second research component to longer-range NWP forecasts. It also applies the verification framework developed in the first research component to evaluate how predictive skill decays with increasing lead times. This evaluation is crucial for understanding the temporal limitations of actionable flash flood predictions.

The following sections outline the methodological decisions (Figure \ref{fig:integrated_experimental_strategy}, row related to the \textit{methodological decisions}) underlying each research component. These decisions encompass three primary areas: the selection of appropriate data sources (Section \ref{experimental_data_requirements}), the formulation of the forecast verification strategy (Section \ref{experimental_design_model_dev_imbalanced_data}), and the strategy for developing a data-driven model to identify areas at risk of flash floods under imbalanced observational datasets (Section \ref{experimental_design_model_dev_imbalanced_data}). 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Data requirements and selection}
\label{experimental_data_requirements}

The development of a flash flood prediction system necessitates careful consideration of data requirements across all methodological components, e.g. model development, forecast verification (at different lead times), and future operational implementation. This section outlines the criteria for selecting the required data to develop a proof of concept of a system that produces medium-range forecasts of areas at risk of flash floods over a continuous global domain (Section \ref{experimental_data_requirements_data_selection_criteria}) and provides the final selection within available sources (Section \ref{experimental_data_requirements_final_selection}). 


\subsection{Criteria for data selection}
\label{experimental_data_requirements_data_selection_criteria}

\subsubsection{Requirements for observational data}

Given \marginpara{Requirement for observational data n.1: spatio-temporal accuracy of reported flash flood events} that flash floods are rapid-onset, localised events typically occurring in small catchments, observational datasets must accurately capture both the location and timing of each event, alongside quantifying the spatio-temporal uncertainty associated with each record. This precision is essential for developing a robust flash-flood-focused verification framework (RQ1), where grid-based assessments require accurate spatial assignment of events to model grid cells. Furthermore, precise spatio-temporal information enables prediction systems — whether data-driven or physics-based — to establish meaningful relationships between local meteorological conditions and flash flood occurrence, thereby capturing the fine-scale processes that govern these rapid-onset events (RQ2 and RQ3).

The \marginpara{Requirement for observational data n.2: long, complete, and consistent timeseries of reported events.} rarity of flash flood events necessitates extensive temporal coverage to accumulate an adequate number of flash flood events for robust forecast verification (RQ1 to RQ3) and data-driven model training (RQ2). Additionally, consistent reporting standards across the considered spatial domain ensure unbiased verification and prevent the introduction of artificial patterns during model training. Moreover, consistent reporting standards would facilitate sensitivity analyses for expanding regional training to global scales, should suitable global databases not be available (RQ2).

\subsubsection{Requirements for hydro-meteorological forecasts}

To \marginpara{Requirements for hydro-meteorological forecasts  n.1: consistent forecasts spatial resolution through the lead time horizon} analyse forecast predictability from short-range (i.e., up to day 1; RQ1 and RQ2) to medium-range lead times (up to day 5; RQ1 and RQ3), a system providing consistent spatial resolution across all lead times would be preferable. Varying resolutions would compound extrinsic uncertainties with those intrinsic ones present in flash flood predictions, arising from both the chaotic nature of flash-flood-generating rainfall events and the complexity of the hydrological processes involved in flash flood generation. Hence, by employing consistent spatial resolution throughout, any lead-time-driven model performance degradation may reflect genuine predictability limits rather than dataset inconsistencies.

Due \marginpara{Requirements for hydro-meteorological forecasts  n.2: capability to represent flash-flood-triggering rainfall events} to their coarse resolution and parametrisation schemes of convective systems, raw global NWP model outputs systematically underestimate localised rainfall extremes, which are critical for flash flood generation. Consequently, both the verification of areas at risk of flash floods (RQ1 to RQ3) and the training of machine learning models for predicting such areas at risk of flash floods (RQ2) require rainfall estimates that can identify flash-flood-triggering rainfall events. 

Whilst \marginpara{Requirements for hydro-meteorological forecasts  n.3: Global coverage} the proof of concept proposed in this thesis focuses in the creation (RQ2 and RQ3) and verification (RQ1 to RQ3) of predictions of areas at risk of flash floods over the CONUS, the methodology must support global extension. This requirement necessitates globally consistent datasets without regional discontinuities, typically provided by global NWP model outputs.


\subsection{Available Data Sources and Final Selection}
\label{experimental_data_requirements_final_selection}

\subsubsection{Observational data}

The \marginpara{Choice of observational data: impact-based reports vs gauge-based measurements} observational data available for this thesis fall into two main categories: impact-based reports and gauge-based measurements. The choice of using impact-based reports rather than gauge-based measurements reflects this thesis's objective to predict areas at risk of both fluvial flash floods - occurring within river channels - and pluvial flash floods - resulting from inadequate urban drainage systems or surface runoff accumulation, including areas away from river channels. Discharge gauges capture only fluvial flash floods, whilst impact databases enable the identification of both fluvial and pluvial events. Furthermore, gauge-based observations systematically underestimate flash flood frequency due to a sparse observational network and the tendency for flashy catchments to remain ungauged \citep{Gaume_2009, Gaume_2016}. Although impact databases are subject to reporting biases — notably those related to population density \citep{Marjerison_2016} — they provide the most feasible approach for developing and verifying continental-scale predictions of areas at risk of flash floods.

This \marginpara{Chosen impact database - NOAA's Storm Event Database over CONUS - and its comparison to alternative databases} thesis employs NOAA's Storm Events Database\footnote{For more details, refer to Section \ref{storm_event_database} in Chapter \ref{datasets}} over the CONUS as the primary observational data source. Compared to other impact databases, the Storm Event Database represents the most comprehensive and systematically maintained record of flash flood impacts available at a continental scale, containing detailed spatio-temporal information from 1996 to the present, including location and reporting time uncertainties for each event. The database's consistent reporting standards across all US states, maintained through NOAA quality control procedures, reduce, though do not eliminate, reporting inconsistencies. Such spatial consistency enables robust model development and forecast verification across CONUS' diverse hydro-climatic regions, while also facilitating sensitivity analyses for expanding regional training to a global scale. Whilst alternative databases exist, they present significant limitations. ESSL's ESWD database lacks direct flash flood reports, recording only "extreme rainfall" events \citep{Dotzek_2009}. Such reports are usually considered as proxies for flash flooding. However, as stated in Chapter \ref{general_introduction}, a direct correlation between rainfall events and flash flood generation is not assumed in this thesis. Furthermore, ESWD presents a spatial bias with disproportionately high observation density over Germany, where ESSL is based \citep{Dotzek_2009}. Such a difference is inconsistent with the literature, which provides no evidence of higher flash flood frequency in Germany relative to neighbouring countries \citep{Gaume_2009}. Hence, if ESWD were the primary observational dataset, errors in the spatial representation of areas at risk of flash floods might be introduced during model training and forecast verification. Global impact databases such as EM-DAT and DesInventar contain an insufficient number of flash flood records due to their inclusion criteria and the inherent difficulty of systematically documenting small-scale events worldwide \citep{Panwar_2020}.

\subsubsection{Hydro-meteorological forecasts}

The \marginpara{Chosen reanalysis and forecasting system for hydrological and static parameters - ERA5} selection of ERA5-related datasets\footnote{For more details, refer to Section \ref{datasets_era5} in Chapter \ref{datasets}} (both reanalysis and medium-range forecasts) reflects a deliberate strategy to maintain consistency across the three research components of this thesis. ERA5 provides a long-term (from the 1940s to the present), high-quality reconstruction of hydrological and static fields over a continuous global domain \citep{Hersbach_2020}.  This temporal extent ensures sufficient historical data to capture the full spectrum of meteorological conditions associated with flash flood events, including rare, extreme scenarios that may occur infrequently within shorter time series. The global coverage and uniform spatial resolution of ERA5 eliminate boundary effects and regional inconsistencies that could compromise model transferability across different geographical domains. Furthermore, the availability of medium-range predictions with the same spatial resolution as the reanalysis data used during model training facilitates the analysis of forecast predictability with minimum disruption due to fine-tuning of low-resolution training datasets to higher-resolution forecasts, as seen in other data-driven systems \citep{Lang_2024}.

While \marginpara{Chosen reanalysis and forecasting system to represent localised extreme rainfall - ERA5-ecPoint} ERA5 provides a consistent dataset for training and prediction across space and time, its coarse resolution (31 km) renders raw ERA5 rainfall estimates unsuitable for flash flood applications. Localised rainfall peaks tend to be underestimated in the case of large-scale rainfall (whether from stratiform rainfall or large convective systems) or absent in the case of isolated convection. Hence, the rainfall estimates used in this thesis for training, model development, and verification come from the post-processed ERA5 rainfall estimates with the ecPoint methodology (ERA5-ecPoint\footnote{For more details, refer to Section \ref{datasets_era5_ecpoint} in Chapter \ref{datasets}}). ERA5-ecPoint provides a probabilistic distribution of the localised extreme rainfall estimates that might be observed by rain gauges within model grid-boxes, being, therefore, more representative of point-scale rainfall's local maxima.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Forecasts verification strategy}
\label{experimental_design_verification_strategy}

\subsection{Criteria to robustly evaluate rare events using underreporting observational datasets}


\subsection{Proposed Forecasts verification strategy}

\begin{figure}[htbp]
\centering
\includegraphics[width=\textwidth]{forecast_evaluatio_strategy.png}
\caption{\textbf{Forecast evaluation strategies.} Draft figure.}
\label{fig:forecast_evaluatio_strategy}
\end{figure}


\begin{figure}[htbp]
\centering
\includegraphics[width=\textwidth]{roc_examples.png}
\caption{\textbf{Examples of ROC and precision-recall curves.} Draft figure.}
\label{fig:roc_examples}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Data-driven model development strategy under imbalanced observational datasets}
\label{experimental_design_model_dev_imbalanced_data}

The development of data-driven models that predict areas at risk of flash floods must confront the fundamental challenge of training such models with extremely imbalanced observational datasets. The yes-event class (i.e. when a flash flood event is reported) represents \sim0.2\% of the total number of reports in the database\footnote{For more details on the representation of yes-events in NOAA's Storm Event Database, please refer to Section \ref{datasets_storm_event_database} in Chapter \ref{datasets}}, creating one of the most severe class imbalance problems encountered in environmental prediction, comparable to the detection of lightning \citep{Cavaiola_2024} or landslides \citep{Xu_2022, Agrawal_2017, Zhang_2022, Gupta_2023}. 

\subsection{Criteria to develop robust data-driven models under imbalanced datasets}

At \marginpara{Criteria to develop robust data-driven models under imbalanced datasets n.2: adoption of algorithm-level and ensemble-level approaches for uncertainty quantification in the data-driven predictions} an initial "proof-of-concept" stage, the need for uncertainty quantification to produce robust models should be satisfied by the use of algorithm- and ensemble-level approaches rather than data-level methods. Algorithm-level approaches modify the learning process through techniques such as weighted learning functions, while ensemble-level methods, such as ensemble-based algorithms (e.g., random forest and boosting) or cross-validation, combine multiple classifiers or train many models over different samples of the training dataset to capture the inherent uncertainties in predictions generated with imbalanced observational datasets. In contrast, data-level approaches, also known as sampling methods, include oversampling, undersampling, and synthetic data generation, which modify the training dataset, altering the original ratio between yes- and no-events and, potentially, obscuring the true rarity of flash flood events and compromising uncertainty estimates. By preserving the original ratio in the observational dataset, the developed models provide probability estimates that may reflect actual flash flood occurrence patterns, and prediction uncertainties may remain interpretable for operational decision-making. Whilst more sophisticated sampling methods may prove beneficial in future development stages, this initial proof-of-concept prioritises approaches that maintain data integrity, establishing a baseline against which more complex systems can be benchmarked.

Data-driven \marginpara{Criteria to develop robust data-driven models under imbalanced datasets n.3: select appropriate evaluation metrics to avoid trivial classifiers} models trained on severely imbalanced datasets risk converging to trivial classifiers that can easily achieve accuracy exceeding 99\% by exclusively predicting non-events. Such a system would indeed provide no operational value. Hence, the model development strategy must employ metrics that can extract the most minimal predictive signal (i.e., identify the yes-events) from a sea of noise (i.e., non-events), while maintaining a low count of false alarms.

\subsection{Proposed strategies and implementation}

To \marginpara{Chosen strategy for developing robust data-driven models under imbalanced datasets: ensemble learning algorithms and weighted loss functions} develop robust data-driven models under imbalanced datasets, this thesis employs three distinct approaches. The model development first incorporates multiple ensemble algorithms, including Random Forest, Gradient Boosting variants (XGBoost, LightGBM, CatBoost), and ensemble stacking methods. Each algorithm offers distinct mechanisms for handling imbalanced datasets without requiring data manipulation. Random Forest creates multiple views of the data through bootstrap sampling, potentially improving the representation of positive events in individual trees. Gradient boosting methods sequentially focus on misclassified examples, progressively enhancing detection of difficult-to-predict positive cases. This algorithmic diversity enables a comprehensive assessment of which approaches best capture the subtle signals preceding flash flood events. To train each of these models, this thesis will test two different loss functions: one that weighs all misclassifications equally, effectively obscuring the importance of correctly identifying rare positive events, such as cross-entropy, and one loss function that directly targets imbalanced datasets, such as "weighted cross-entropy". Both sets of forecasts will be evaluated and compared to assess which approach might yield better results. Finally, even though each of the classifiers mentioned above is considered an ensemble technique, the corresponding outputs are created with a deterministic configuration, which says very little about the uncertainty around the predictions and the generalisation performance of the models. Hence, multiple configurations for each classifier (and loss function) will be created by applying the "k-fold cross-validation" approach. Moreover, the consolidated configuration for each classifier will be combined through the "ensemble stacking" technique, a meta-learning technique that optimally blends individual classifier outputs to produce robust final predictions with associated uncertainty estimates.

The \marginpara{Chosen robust evaluation metrics: area under the precision-recall curve (AUPRC) vs. area under the ROC curve (AROC} evaluation framework employs metrics specifically designed for imbalanced classification problems. A commonly used metric consists of the area under the ROC curve (AROC, which balances hit rates and false alarms. As explained in Section \ref{experimental_design_verification_strategy}, AROC is a measure of the prediction's discrimination ability (i.e. the system's ability to distinguish between yes-events and non-events). Since uncalibrated forecasts may yield higher values of AROC by overestimating the probability of flash flood occurrence, choosing this evaluation metric for hyperparameter optimisation or evaluation of forecasts over unseen test data may mean seeking a system that does not miss events, even at the expense of generating more false alarms. Another popular evaluation metric in the domain of data-driven model development is the area under the precision-recall curve. In this case, the focus lies on balancing precision (the fraction of predicted events that materialise) and recall (the fraction of actual events successfully predicted, also known as hit rates). Hence, choosing this evaluation metric may mean seeking a system that provides better-calibrated forecasts to identify yes-events, but by limiting the number of false alarms. The literature remains divided on which of these two popular evaluation metrics is likely to yield the best results \citep{Richardson_2024, Saito_2015}. Hence, this thesis presents results obtained using both evaluation metrics.


%%%%%%%%%%%%%%%%%
\section{Summary}

This chapter has articulated an integrated experimental design that systematically addresses the challenge of producing medium-range predictions of areas at risk of flash floods across a continuous global domain. The methodological framework illustrates how seemingly distinct research components converge into a coherent strategy, with each element carefully chosen to support the overarching research questions in this thesis. This integrated design acknowledges that flash flood prediction represents a cascade of uncertainties. By maintaining methodological consistency whilst allowing component-specific optimisation, the framework provides a robust platform for advancing operational flash flood prediction capabilities. The subsequent \textit{Main Analysis} chapters (\ref{flash_flood_focused_verification_framework} to \ref{predictability_PoFF}) will implement this experimental design, progressively building from fundamental verification principles through regional model development of short- and medium-range forecasts, to the extension of predictions over a continuous global domain.